

```{python}
import numpy as np
import pandas as pd
import statsmodels.api as sm
import matplotlib.pyplot as plt
```

```{python}
octo=pd.read_csv("octopus_prices_full_2025.csv")
octo.head()
```


```{python}
octo.info()
```



```{python}
octo = octo.drop(columns=["payment_method", "valid_to", "value_exc_vat"])
octo["valid_from"]=pd.to_datetime(octo["valid_from"])
octo.set_index("valid_from", inplace=True)
```


# SMOOTHING

```{python}
plt.plot(octo.loc["2025-01-01"])
plt.plot(octo.loc["2025-01-01"].rolling(6).mean())
```


```{python}
octo.rolling(24*30).mean().plot()
```


```{python}
octo["ND"].plot(kind="hist")
```
```{python}
demand = pd.read_csv("demand_data_2025.csv")
```
```{python}
demand["ND"].plot(kind="hist")
```
```{python}
demand["ND"].plot()
```
```{python}
demand["ND"].sum()
```
```{python}
demand[]
```
```{python}
import seaborn as sns
sns.boxenplot(demand["ND"])
```
```{python}
fig, ax=plt.subplots(nrows=1,ncols=2)

ax[0].boxplot(demand["ND"])
ax[1].hist(demand["ND"])
```

```{python}
demand.head()

```
```{python}
demand["ND"].idxmax()
```
```{python}
demand.iloc[148].to_frame().transpose()
```
```{python}
fig, ax=plt.subplots(figsize=(12,8))
sns.heatmap(demand.corr(numeric_only=True), annot = True, ax=ax)
```
```{python}
demand_2024=pd.read_csv("demand_data_2024.csv")
```
```{python}
demand.info()
```
```{python}
demand_24_25 = pd.concat([demand, demand_2024]).reset_index()
```
```{python}
demand_24_25.to_csv("demand_24_25.csv", index=False)
```
```{python}
demand_2023 = pd.read_csv("demand_data_2023.csv")
```
```{python}
demand_2023.info()
```
```{python}
demand_2023_2024_2025 = pd.concat([demand_24_25, demand_2023]).reset_index()
````
```{python}
demand_2023_2024_2025.info()
```
```{python}
demand_2023_2024_2025 = demand_2023_2024_2025.drop(columns=["level_0", "index"])

```
```{python}
demand_2023_2024_2025.head()
```
```{python}
demand_2023_2024_2025["SETTLEMENT_DATE"] = pd.to_datetime(demand_2023_2024_2025["SETTLEMENT_DATE"], format="mixed")
```
```{python}
demand_2023_2024_2025.set_index("SETTLEMENT_DATE", inplace=True)
```
```{python}
demand_2023_2024_2025.tail()
```
```{python}
demand_2023_2024_2025.head()
```
```{python}
demand_2023_2024_2025.resample("QE").sum()["ND"].plot(kind="bar")
```
```{python}
demand_2023_2024_2025.to_csv("demand_23_24_25.csv", index=False)
```
```{python}
octo.head()
```

```{python}
import pandas as pd
octo=pd.read_csv("octopus_prices_full_2025.csv")
```

```{python}
octo = (octo.assign(valid_from = pd.to_datetime(octo["valid_from"]))
    .drop(columns=["value_exc_vat", "valid_to", "payment_method"])
    .set_index("valid_from")
)
```

```{python}
octo = octo.reset_index()
octo = octo.assign(
    trend = octo.index,
    #hour = octo["valid_from"].dt.hour.astype("string"),
    slot = octo["valid_from"].dt.strftime("%H:%M")
).set_index("valid_from")


octo = pd.get_dummies(octo, columns=["slot"], drop_first=True, dtype="int")

octo["trend"] = range(len(octo))

# Create a feature for the price 30 mins ago
octo['price_lag_1'] = octo['value_inc_vat'].shift(1)
#octo["hour"] = octo["hour"].astype("int")
 
# IMPORTANT: You must drop the first row because it won't have a previous price
octo = octo.dropna()

#octo.head()
```


```{python}

import statsmodels.api as sm


octo_train = octo.loc["2025-01-01": "2025-01-31"]
octo_test  = octo.loc["2025-02-01": "2025-02-07"]


X_train = sm.add_constant(octo_train.drop("value_inc_vat", axis=1))
y_train = octo_train["value_inc_vat"]

X_test = sm.add_constant(octo_test.drop("value_inc_vat", axis=1))
Y_test = octo_test["value_inc_vat"]
```
```{python}
import statsmodels.api as sm

model = sm.OLS(y_train, X_train).fit()
model.summary()
```
```{python}
octo.head()
```
```{python}
octo.info()
```
```{python}
import matplotlib.pyplot as plt

# 1. Generate predictions
test_preds = model.predict(X_test)

# 2. Plotting
plt.figure(figsize=(12, 6))
plt.plot(Y_test.index, Y_test, label='Actual Price', alpha=0.7, color='blue')
plt.plot(Y_test.index, test_preds, label='Predicted Price', alpha=0.7, color='orange', linestyle='--')

plt.title('Octopus Agile Price Prediction: Actual vs Predicted (Feb 2025)')
plt.ylabel('Price (inc VAT)')
plt.legend()
plt.grid(True, alpha=0.3)
plt.show()
```
```{python}
from sklearn.metrics import mean_absolute_error, mean_squared_error
import numpy as np

# Calculate metrics
mae = mean_absolute_error(Y_test, test_preds)
rmse = np.sqrt(mean_squared_error(Y_test, test_preds))

print(f"Mean Absolute Error (MAE): {mae:.2f}p")
print(f"Root Mean Squared Error (RMSE): {rmse:.2f}p")
```
```{python}
import pandas as pd

# Create the comparison table
comparison_df = pd.DataFrame({
    'Actual Price': Y_test,
    'Predicted Price': test_preds,
    'Error (p)': Y_test - test_preds
}).round(2)

# Display the first 10 rows
print(comparison_df.head(10))
```
```{python}
# 1. Apply absolute value to the Error column first
comparison_df['Abs_Error'] = comparison_df['Error (p)'].abs()

# 2. Group by slot and calculate the mean of that absolute error
error_by_slot = comparison_df.groupby('Slot')['Abs_Error'].mean().sort_values(ascending=False)

print("Top 5 hardest slots to predict (highest MAE in p):")
print(error_by_slot.head(5))


```
```{python}
import numpy as np
import pandas as pd
import statsmodels.api as sm

# 1. Identify the last known price and time
last_time = octo.index[-1]
last_price = octo['value_inc_vat'].iloc[-1]

# 2. Create the next two timestamps
future_times = pd.date_range(start=last_time + pd.Timedelta(minutes=30), periods=2, freq='30T')

# 3. Build the feature DataFrame
future_df = pd.DataFrame(index=future_times)
future_df['trend'] = octo['trend'].iloc[-1] + np.array([1, 2])
future_df['slot'] = future_df.index.strftime("%H:%M")

# 4. Create dummies and align columns with X_train
future_df = pd.get_dummies(future_df, columns=['slot'], dtype=int)
# This step ensures the new DF has all 47 slot columns, filled with 0 where appropriate
future_df = future_df.reindex(columns=X_train.columns.drop('price_lag_1'), fill_value=0)
```
```{python}
predictions = []
current_lag = last_price

# Ensure we are using the exact column list from the training set
model_features = X_train.columns.tolist()

for i in range(len(future_df)):
    # 1. Prepare the row and add the lag
    row = future_df.iloc[[i]].copy()
    row['price_lag_1'] = current_lag
    
    # 2. Add the constant column ('const') manually to match X_train
    if 'const' not in row.columns:
        row['const'] = 1.0
    
    # 3. FORCE the columns to be in the exact same order as X_train
    # This removes any extra columns and fixes the "alignment" error
    row_aligned = row[model_features]
    
    # 4. Predict
    pred = model.predict(row_aligned)[0]
    predictions.append(pred)
    
    # 5. Update lag for the next step
    current_lag = pred

# Display results
for time, p in zip(future_times, predictions):
    print(f"Predicted Price for {time.strftime('%H:%M')}: {p:.2f}p")
```
```{python}
import pandas as pd
import numpy as np

# 1. Identify the last actual price (from the 11:00 slot)
# Replace this with your actual data lookup
last_actual_price = octo.loc[octo.index.strftime('%H:%M') == '23:00', 'value_inc_vat'].iloc[-1]

# 2. Define the future slots
future_slots = ['23:00', '23:30']
model_features = X_train.columns.tolist()

# 3. Recursive Loop
current_lag = last_actual_price
predictions = {}

for slot in future_slots:
    # Create a single-row DataFrame for this slot
    row = pd.DataFrame(columns=model_features, index=[0])
    row.fillna(0, inplace=True) # Set all slot dummies to 0
    
    # Set the specific features
    row['const'] = 1.0
    row['price_lag_1'] = current_lag
    row['trend'] = octo['trend'].max() + 1 # Increment your trend
    
    # Set the dummy for the specific slot to 1
    slot_col = f'slot_{slot}'
    if slot_col in row.columns:
        row[slot_col] = 1
    
    # Predict
    pred = model.predict(row[model_features])[0]
    predictions[slot] = pred
    
    # Update the lag for the next iteration
    current_lag = pred

print(f"Predicted Price for 23:00: {predictions['23:00']:.2f}p")
print(f"Predicted Price for 23:30: {predictions['23:30']:.2f}p")
```